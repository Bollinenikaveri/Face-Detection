{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQRFMxoKNDWq+0Y3j85YDE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bollinenikaveri/Face-Detection/blob/main/face_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ7qcDC9ZN0_",
        "outputId": "1b1effd6-4fc1-47c9-c81d-497264cfbb7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display,Javascript"
      ],
      "metadata": {
        "id": "CO2XwXBbZsEP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.output import eval_js"
      ],
      "metadata": {
        "id": "qxPWj7StZ6kd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from base64 import b64decode"
      ],
      "metadata": {
        "id": "EtWzGBkUZ6mn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "GitziMyOZ6qS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ab68DEa1ZsGi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zfzIHt8mZsJ4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "yTYFlI0caQXz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io"
      ],
      "metadata": {
        "id": "iObgr4ifaQY_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_webcam():\n",
        "  js = Javascript('''async function startWebcam(){\n",
        "  const video =documnet.createElement('video');\n",
        "  document.body.appendChild(video);\n",
        "  video.style.display='block';\n",
        "  const stream=await navigator.mediaDevices.getUserMedia({video:true});\n",
        "  video.srcObject =stream;\n",
        "  await video.play();\n",
        "  const canvas=document.createElement('canvas');\n",
        "  canvas.width=video.videoWith;\n",
        "  canvas.height=video.videoHeight;\n",
        "  return video;\n",
        "  }\n",
        "  ''')\n",
        "  display(js)\n",
        "  return eval_js('startWebcam()')"
      ],
      "metadata": {
        "id": "e1BSgYLhatdE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -N https://raw.githubusercontent.com/opencv/master/simple/dnn/face_detector/deploy.prototxt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuwcR72katgZ",
        "outputId": "5341f760-d3b7-4c8c-cc0f-2223ba53d7d3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-02 11:50:16--  https://raw.githubusercontent.com/opencv/master/simple/dnn/face_detector/deploy.prototxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-02-02 11:50:16 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -N https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samoles_face_detector_20180205_fp16/res10_300*300_ssd_iter_140000_fp16.caffemodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3uJVmqwaQci",
        "outputId": "6ba9c08a-7503-4ceb-8ab5-9eb38971c96a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: wildcards not supported in HTTP.\n",
            "--2025-02-02 11:50:31--  https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samoles_face_detector_20180205_fp16/res10_300*300_ssd_iter_140000_fp16.caffemodel\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-02-02 11:50:31 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LM_WA_85gqQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -N https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvSWoym4fvwa",
        "outputId": "5ae4640b-f325-4fd6-c322-6439d8d71773"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-02 11:54:07--  https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5351047 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘res10_300x300_ssd_iter_140000_fp16.caffemodel’\n",
            "\n",
            "res10_300x300_ssd_i 100%[===================>]   5.10M  --.-KB/s    in 0.09s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2025-02-02 11:54:07 (57.6 MB/s) - ‘res10_300x300_ssd_iter_140000_fp16.caffemodel’ saved [5351047/5351047]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -N https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
        "!wget -N https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel\n",
        "\n",
        "net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'res10_300x300_ssd_iter_140000_fp16.caffemodel')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpefZvnyij4b",
        "outputId": "7bff257b-bbb4-4110-fbdf-d2bffcbc6b53"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-02 12:02:20--  https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28104 (27K) [text/plain]\n",
            "Saving to: ‘deploy.prototxt’\n",
            "\n",
            "deploy.prototxt     100%[===================>]  27.45K  --.-KB/s    in 0.002s  \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2025-02-02 12:02:21 (17.1 MB/s) - ‘deploy.prototxt’ saved [28104/28104]\n",
            "\n",
            "--2025-02-02 12:02:21--  https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5351047 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘res10_300x300_ssd_iter_140000_fp16.caffemodel’\n",
            "\n",
            "res10_300x300_ssd_i 100%[===================>]   5.10M  --.-KB/s    in 0.08s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2025-02-02 12:02:21 (60.1 MB/s) - ‘res10_300x300_ssd_iter_140000_fp16.caffemodel’ saved [5351047/5351047]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_faces(frame):\n",
        "  (h, w) = frame.shape[:2]\n",
        "  blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "  net.setInput(blob)\n",
        "  detections = net.forward()\n",
        "  face_count = 0\n",
        "  for i in range(0, detections.shape[2]):\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "    if confidence > 0.5:\n",
        "      face_count += 1\n",
        "      box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "      (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "      cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "  cv2.putText(frame, f'Faces: {face_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "  return frame"
      ],
      "metadata": {
        "id": "tOFEa-g8ij-A"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_webcam():\n",
        "  js = Javascript('''async function startWebcam(){\n",
        "  const video = document.createElement('video'); # Corrected 'documnet' to 'document'\n",
        "  document.body.appendChild(video);\n",
        "  video.style.display='block';\n",
        "  const stream=await navigator.mediaDevices.getUserMedia({video:true});\n",
        "  video.srcObject =stream;\n",
        "  await video.play();\n",
        "  const canvas=document.createElement('canvas');\n",
        "  canvas.width=video.videoWith;\n",
        "  canvas.height=video.videoHeight;\n",
        "  return video;\n",
        "  }\n",
        "  ''')\n",
        "  display(js)\n",
        "  return eval_js('startWebcam()')"
      ],
      "metadata": {
        "id": "R5zRI0QWnM14"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_vYzUernM8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from google.colab.output import eval_js, register_callback\n",
        "import time\n",
        "\n",
        "# Load face detection model\n",
        "prototxt_url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt'\n",
        "caffemodel_url = 'https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
        "\n",
        "!wget -q {prototxt_url} -O deploy.prototxt\n",
        "!wget -q {caffemodel_url} -O res10_300x300_ssd_iter_140000_fp16.caffemodel\n",
        "\n",
        "net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'res10_300x300_ssd_iter_140000_fp16.caffemodel')\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Wait for Capture to be clicked\n",
        "            return new Promise((resolve) => {\n",
        "                capture.onclick = () => {\n",
        "                    const canvas = document.createElement('canvas');\n",
        "                    canvas.width = video.videoWidth;\n",
        "                    canvas.height = video.videoHeight;\n",
        "                    canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "                    video.srcObject.getTracks().forEach(track => track.stop());\n",
        "                    div.remove();\n",
        "                    resolve(canvas.toDataURL('image/jpeg', quality));\n",
        "                };\n",
        "            });\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "    data = eval_js('takePhoto(0.8)')\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    return cv2.imdecode(np.frombuffer(binary, dtype=np.uint8), -1)\n",
        "\n",
        "def detect_faces(frame):\n",
        "    (h, w) = frame.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n",
        "                               (300, 300), (104.0, 177.0, 123.0))\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "\n",
        "    face_count = 0\n",
        "    for i in range(0, detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence > 0.5:\n",
        "            face_count += 1\n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
        "\n",
        "    cv2.putText(frame, f'Faces: {face_count}', (10, 30),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "    return frame\n",
        "\n",
        "# Main execution loop\n",
        "while True:\n",
        "    try:\n",
        "        frame = take_photo()\n",
        "        frame = detect_faces(frame)\n",
        "        cv2_imshow(frame)\n",
        "        time.sleep(0.1)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Stopped\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "wFwxmoe_nNGF",
        "outputId": "dbc021bc-d449-4b09-9704-9fb7a763844a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Wait for Capture to be clicked\n",
              "            return new Promise((resolve) => {\n",
              "                capture.onclick = () => {\n",
              "                    const canvas = document.createElement('canvas');\n",
              "                    canvas.width = video.videoWidth;\n",
              "                    canvas.height = video.videoHeight;\n",
              "                    canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                    video.srcObject.getTracks().forEach(track => track.stop());\n",
              "                    div.remove();\n",
              "                    resolve(canvas.toDataURL('image/jpeg', quality));\n",
              "                };\n",
              "            });\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped\n"
          ]
        }
      ]
    }
  ]
}